{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accessory-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoadVars import *\n",
    "from ga import *\n",
    "from NeuralNet import NeuralNet, train, calculate\n",
    "from performance import calc_hv\n",
    "from SaveOutput import save\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "partial-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The benchmark problem: OSY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Defining problem\n",
    "problem = define_problem(problem_name)\n",
    "pareto_front = problem.pareto_front()\n",
    "print(f'The benchmark problem: {problem_name.upper()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "geological-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing initial sampling: REAL_LHS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initial sampling\n",
    "initial_sampling = define_sampling(initial_sampling_method_name)\n",
    "print(f'Performing initial sampling: {initial_sampling_method_name.upper()}\\n')\n",
    "InitialData = initial_sampling.do(problem, n_samples=pop_size, pop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expressed-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating initial samples (true eval)\n",
    "InitialEval = problem.evaluate(InitialData, return_values_of=['F'])\n",
    "InitialEval_G = problem.evaluate(InitialData, return_values_of=['G'])\n",
    "InitialEval_CV = problem.evaluate(InitialData, return_values_of=['CV'])\n",
    "\n",
    "if InitialEval_G is not None:\n",
    "\tInitialEval = np.concatenate((InitialEval, InitialEval_G, InitialEval_CV), axis=1)\n",
    "\n",
    "save('OUTPUT/initial_pop_X.dat', InitialData, header='#Generation 1: X')\n",
    "save('OUTPUT/initial_pop_FGCV.dat', InitialEval, header='#Generation 1: F, G, CV')\n",
    "save('OUTPUT/all_pop_X.dat', InitialData, header='Generation 1: X')\n",
    "save('OUTPUT/all_pop_FGCV.dat', InitialEval, header='Generation 1: F, G, CV')\n",
    "save('DATA/training/X.dat', InitialData)\n",
    "save('DATA/training/OUT.dat', InitialEval[:, 0:problem.n_obj+problem.n_constr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southwest-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial performance\n",
    "HV = [0.0]\n",
    "HV += [calc_hv(InitialEval[:,range(problem.n_obj)], ref=hv_ref)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amended-length",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding the training data to the neural net...\n",
      "\n",
      "\n",
      "Performing initial training...\n",
      "\n",
      "N_Epoch = 0 Loss = 24.511734008789062\n",
      "N_Epoch = 100 Loss = 0.4098881781101227\n",
      "N_Epoch = 200 Loss = 0.38681069016456604\n",
      "N_Epoch = 300 Loss = 0.34612932801246643\n",
      "N_Epoch = 400 Loss = 0.269835501909256\n",
      "N_Epoch = 500 Loss = 0.17243728041648865\n",
      "N_Epoch = 600 Loss = 0.08344240486621857\n",
      "N_Epoch = 700 Loss = 0.043640412390232086\n",
      "N_Epoch = 800 Loss = 0.02196873165667057\n",
      "\n",
      "An initial trained model is obtained!\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Initial training for neural nets\n",
    "print('Feeding the training data to the neural net...\\n\\n')\n",
    "\n",
    "Model = NeuralNet(D_in=problem.n_var,\n",
    "\t\t\t\t  H=N_Neuron, D=N_Neuron,\n",
    "\t\t\t\t  D_out=problem.n_obj+problem.n_constr)\n",
    "\n",
    "print('Performing initial training...\\n')\n",
    "\n",
    "TrainedModel = train(problem=problem,\n",
    "\t\t\t\t\t model=Model,\n",
    "\t\t\t\t     N_Epoch=N_Epoch,\n",
    "\t\t\t\t     lr=lr,\n",
    "\t\t\t\t     batchrate=batchrate)\n",
    "print('\\nAn initial trained model is obtained!\\n')\n",
    "print('--------------------------------------------------')\n",
    "TrainedModel_Problem = TrainedModelProblem(problem, TrainedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lined-indonesian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing optimization on the initial trained model using NSGA2\n",
      "\n",
      "=====================================================================================\n",
      "n_gen |  n_eval |   cv (min)   |   cv (avg)   |  n_nds  |     eps      |  indicator  \n",
      "=====================================================================================\n",
      "    1 |     100 |  3.946895063 |  1.27354E+01 |       1 |            - |            -\n",
      "    2 |     200 |  3.893940032 |  7.771185580 |       1 |      26.3302 |        ideal\n",
      "    3 |     300 |  3.614712000 |  5.624607941 |       1 |     9.530151 |        ideal\n",
      "    4 |     400 |  3.387912214 |  4.503499701 |       1 |    4.6553955 |        ideal\n",
      "    5 |     500 |  3.387912214 |  3.990491118 |       1 |  0.00000E+00 |            f\n",
      "    6 |     600 |  3.322402537 |  3.692812963 |       1 |    6.0720215 |        ideal\n",
      "    7 |     700 |  3.202178717 |  3.519517620 |       1 |     6.963867 |        ideal\n",
      "    8 |     800 |  3.191092014 |  3.426038094 |       1 |    6.8904076 |        ideal\n",
      "    9 |     900 |  3.171473324 |  3.363428976 |       1 |      8.01759 |        ideal\n",
      "   10 |    1000 |  3.158424139 |  3.306114809 |       1 |    2.2176514 |        ideal\n",
      "   11 |    1100 |  3.158424139 |  3.256598636 |       1 |  0.00000E+00 |            f\n",
      "   12 |    1200 |  3.158424139 |  3.218351077 |       1 |  0.00000E+00 |            f\n",
      "   13 |    1300 |  3.158410072 |  3.195938016 |       1 | 0.0037002563 |        ideal\n",
      "   14 |    1400 |  3.137847662 |  3.179162759 |       1 |     3.947754 |        ideal\n",
      "   15 |    1500 |  3.137847662 |  3.167013337 |       1 |  0.00000E+00 |            f\n",
      "   16 |    1600 |  3.137847662 |  3.159083669 |       1 |  0.00000E+00 |            f\n",
      "   17 |    1700 |  3.137847662 |  3.155081397 |       1 |  0.00000E+00 |            f\n",
      "   18 |    1800 |  3.137847662 |  3.151238117 |       1 |  0.00000E+00 |            f\n",
      "   19 |    1900 |  3.127328813 |  3.147187802 |       1 |    1.5189209 |        ideal\n",
      "   20 |    2000 |  3.127328813 |  3.143045644 |       1 |  0.00000E+00 |            f\n",
      "   21 |    2100 |  3.125325322 |  3.140606927 |       1 |    1.4844856 |        ideal\n",
      "   22 |    2200 |  3.125325322 |  3.137879987 |       1 |  0.00000E+00 |            f\n",
      "   23 |    2300 |  3.124050379 |  3.134538930 |       1 |    3.1170578 |        ideal\n",
      "   24 |    2400 |  3.124050379 |  3.129466934 |       1 |  0.00000E+00 |            f\n",
      "   25 |    2500 |  3.120701671 |  3.126887039 |       1 |    2.6940384 |        ideal\n",
      "   26 |    2600 |  3.117933512 |  3.125538150 |       1 |    2.9868393 |        ideal\n",
      "   27 |    2700 |  3.117933512 |  3.124338844 |       1 |  0.00000E+00 |            f\n",
      "   28 |    2800 |  3.117534339 |  3.123411693 |       1 |     2.613449 |        ideal\n",
      "   29 |    2900 |  3.117534339 |  3.122447000 |       1 |  0.00000E+00 |            f\n",
      "   30 |    3000 |  3.117534339 |  3.121709275 |       1 |  0.00000E+00 |            f\n",
      "   31 |    3100 |  3.117089868 |  3.120398579 |       1 |    1.0393219 |        ideal\n",
      "   32 |    3200 |  3.116077542 |  3.119498696 |       1 |   0.36239624 |        ideal\n",
      "   33 |    3300 |  3.116077542 |  3.118869166 |       1 |  0.00000E+00 |            f\n",
      "   34 |    3400 |  3.116077542 |  3.118337760 |       1 |  0.00000E+00 |            f\n",
      "   35 |    3500 |  3.115752637 |  3.117725679 |       1 |    0.6185303 |        ideal\n",
      "   36 |    3600 |  3.115688086 |  3.117444158 |       1 | 0.0056152344 |        ideal\n",
      "   37 |    3700 |  3.115688086 |  3.117221994 |       1 |  0.00000E+00 |            f\n",
      "   38 |    3800 |  3.115688086 |  3.117010484 |       1 |  0.00000E+00 |            f\n",
      "   39 |    3900 |  3.114789128 |  3.116765128 |       1 |    0.6251221 |        ideal\n",
      "   40 |    4000 |  3.114789128 |  3.116419126 |       1 |  0.00000E+00 |            f\n",
      "   41 |    4100 |  3.114557862 |  3.116198151 |       1 |   0.13769531 |        ideal\n",
      "   42 |    4200 |  3.114329278 |  3.115954434 |       1 |   0.76257706 |        ideal\n",
      "   43 |    4300 |  3.114238799 |  3.115811491 |       1 |    0.8589363 |        ideal\n",
      "   44 |    4400 |  3.114238799 |  3.115625845 |       1 |  0.00000E+00 |            f\n",
      "   45 |    4500 |  3.114147067 |  3.115443819 |       1 |   0.24234772 |        ideal\n",
      "   46 |    4600 |  3.114106536 |  3.115253335 |       1 |   0.10686493 |        ideal\n",
      "   47 |    4700 |  3.114065886 |  3.114973372 |       1 | 0.0076675415 |        ideal\n",
      "   48 |    4800 |  3.114065886 |  3.114706513 |       1 |  0.00000E+00 |            f\n",
      "   49 |    4900 |  3.114035249 |  3.114431415 |       1 |   0.42760468 |        ideal\n",
      "   50 |    5000 |  3.114027441 |  3.114267608 |       1 |   0.48008728 |        ideal\n",
      "   51 |    5100 |  3.113725424 |  3.114162020 |       1 |    0.1811943 |        ideal\n",
      "   52 |    5200 |  3.113725424 |  3.114112650 |       1 |  0.00000E+00 |            f\n",
      "   53 |    5300 |  3.113725424 |  3.114073636 |       1 |  0.00000E+00 |            f\n",
      "   54 |    5400 |  3.113725424 |  3.114047313 |       1 |  0.00000E+00 |            f\n",
      "   55 |    5500 |  3.113725424 |  3.114017379 |       1 |  0.00000E+00 |            f\n",
      "   56 |    5600 |  3.113725424 |  3.114000076 |       1 |  0.00000E+00 |            f\n",
      "   57 |    5700 |  3.113717973 |  3.113966559 |       1 |  1.64740E+26 |            f\n",
      "   58 |    5800 |  3.113717973 |  3.113936747 |       1 |  0.00000E+00 |            f\n",
      "   59 |    5900 |  3.113717973 |  3.113901823 |       1 |  0.00000E+00 |            f\n",
      "   60 |    6000 |  3.113573670 |  3.113856674 |       1 |  0.011692047 |        ideal\n",
      "   61 |    6100 |  3.113543093 |  3.113790440 |       1 |     0.054039 |        ideal\n",
      "   62 |    6200 |  3.113542616 |  3.113752246 |       1 |  2.45597E+26 |            f\n",
      "   63 |    6300 |  3.113542616 |  3.113715971 |       1 |  0.00000E+00 |            f\n",
      "   64 |    6400 |  3.113511801 |  3.113675423 |       1 |  0.041873932 |        ideal\n",
      "   65 |    6500 |  3.113511801 |  3.113635355 |       1 |  0.00000E+00 |            f\n",
      "   66 |    6600 |  3.113511801 |  3.113594716 |       1 |  0.00000E+00 |            f\n",
      "   67 |    6700 |  3.113511801 |  3.113554268 |       1 |  0.00000E+00 |            f\n",
      "   68 |    6800 |  3.113511801 |  3.113544607 |       1 |  0.00000E+00 |            f\n",
      "   69 |    6900 |  3.113510847 |  3.113538236 |       1 |  7.64806E+26 |            f\n",
      "   70 |    7000 |  3.113508344 |  3.113531259 |       1 |  2.60334E+27 |            f\n",
      "   71 |    7100 |  3.113508344 |  3.113524379 |       1 |  0.00000E+00 |            f\n",
      "   72 |    7200 |  3.113508344 |  3.113519366 |       1 |  0.00000E+00 |            f\n",
      "   73 |    7300 |  3.113506198 |  3.113515219 |       1 |   0.03453064 |        ideal\n",
      "   74 |    7400 |  3.113500357 |  3.113513142 |       1 |  0.011669159 |        ideal\n",
      "   75 |    7500 |  3.113498211 |  3.113511468 |       1 |  2.44617E+26 |            f\n",
      "   76 |    7600 |  3.113491297 |  3.113510239 |       1 | 0.0040626526 |        ideal\n",
      "   77 |    7700 |  3.113491297 |  3.113508808 |       1 |  0.00000E+00 |            f\n",
      "   78 |    7800 |  3.113490641 |  3.113507470 |       1 |  2.44141E+26 |            f\n",
      "   79 |    7900 |  3.113490641 |  3.113506553 |       1 |  0.00000E+00 |            f\n",
      "   80 |    8000 |  3.113490224 |  3.113505626 |       1 |  5.66479E+26 |            f\n",
      "   81 |    8100 |  3.113489032 |  3.113503417 |       1 |  8.11016E+26 |            f\n",
      "   82 |    8200 |  3.113489032 |  3.113501539 |       1 |  0.00000E+00 |            f\n",
      "   83 |    8300 |  3.113488436 |  3.113498372 |       1 |  0.00000E+00 |            f\n",
      "   84 |    8400 |  3.113488436 |  3.113495206 |       1 |  0.00000E+00 |            f\n",
      "   85 |    8500 |  3.113488436 |  3.113493325 |       1 |  0.00000E+00 |            f\n",
      "   86 |    8600 |  3.113488436 |  3.113492268 |       1 |  0.00000E+00 |            f\n",
      "   87 |    8700 |  3.113488436 |  3.113491759 |       1 |  0.00000E+00 |            f\n",
      "   88 |    8800 |  3.113488436 |  3.113491507 |       1 |  0.00000E+00 |            f\n",
      "   89 |    8900 |  3.113488436 |  3.113491169 |       1 |  0.00000E+00 |            f\n",
      "   90 |    9000 |  3.113487363 |  3.113490807 |       1 |  1.27892E+26 |            f\n",
      "   91 |    9100 |  3.113487363 |  3.113490532 |       1 |  0.00000E+00 |            f\n",
      "   92 |    9200 |  3.113487363 |  3.113490084 |       1 |  0.00000E+00 |            f\n",
      "   93 |    9300 |  3.113487363 |  3.113489671 |       1 |  0.00000E+00 |            f\n",
      "   94 |    9400 |  3.113487363 |  3.113489349 |       1 |  0.00000E+00 |            f\n",
      "   95 |    9500 |  3.113487363 |  3.113489070 |       1 |  0.00000E+00 |            f\n",
      "   96 |    9600 |  3.113486707 |  3.113488770 |       1 |  2.28882E+25 |            f\n",
      "   97 |    9700 |  3.113486707 |  3.113488603 |       1 |  0.00000E+00 |            f\n",
      "   98 |    9800 |  3.113486707 |  3.113488449 |       1 |  0.00000E+00 |            f\n",
      "   99 |    9900 |  3.113485932 |  3.113488285 |       1 |  2.28882E+25 |            f\n",
      "  100 |   10000 |  3.113485932 |  3.113488189 |       1 |  0.00000E+00 |            f\n",
      "  101 |   10100 |  3.113485932 |  3.113488001 |       1 |  0.00000E+00 |            f\n",
      "  102 |   10200 |  3.113485932 |  3.113487815 |       1 |  0.00000E+00 |            f\n",
      "  103 |   10300 |  3.113485932 |  3.113487594 |       1 |  0.00000E+00 |            f\n",
      "  104 |   10400 |  3.113485932 |  3.113487383 |       1 |  0.00000E+00 |            f\n",
      "  105 |   10500 |  3.113485932 |  3.113487157 |       1 |  0.00000E+00 |            f\n",
      "  106 |   10600 |  3.113485932 |  3.113486921 |       1 |  0.00000E+00 |            f\n",
      "  107 |   10700 |  3.113485932 |  3.113486630 |       1 |  0.00000E+00 |            f\n",
      "  108 |   10800 |  3.113485932 |  3.113486367 |       1 |  0.00000E+00 |            f\n",
      "  109 |   10900 |  3.113485932 |  3.113486283 |       1 |  0.00000E+00 |            f\n",
      "  110 |   11000 |  3.113485932 |  3.113486207 |       1 |  0.00000E+00 |            f\n",
      "  111 |   11100 |  3.113485932 |  3.113486121 |       1 |  0.00000E+00 |            f\n",
      "  112 |   11200 |  3.113406599 |  3.113485198 |       1 |  0.046188354 |        ideal\n",
      "  113 |   11300 |  3.113406599 |  3.113484390 |       1 |  0.00000E+00 |            f\n",
      "  114 |   11400 |  3.113406599 |  3.113484380 |       1 |  0.00000E+00 |            f\n",
      "  115 |   11500 |  3.113406599 |  3.113482847 |       1 |  0.00000E+00 |            f\n",
      "  116 |   11600 |  3.113406599 |  3.113481305 |       1 |  0.00000E+00 |            f\n",
      "  117 |   11700 |  3.113401592 |  3.113472977 |       1 | 0.0048294067 |        ideal\n",
      "  118 |   11800 |  3.113399148 |  3.113464221 |       1 |  1.59748E+27 |            f\n",
      "  119 |   11900 |  3.113395751 |  3.113449441 |       1 |  2.78264E+26 |            f\n",
      "  120 |   12000 |  3.113395751 |  3.113425899 |       1 |  0.00000E+00 |            f\n",
      "  121 |   12100 |  3.113395751 |  3.113406646 |       1 |  0.00000E+00 |            f\n",
      "  122 |   12200 |  3.113395751 |  3.113404113 |       1 |  0.00000E+00 |            f\n",
      "  123 |   12300 |  3.113395751 |  3.113402304 |       1 |  0.00000E+00 |            f\n",
      "  124 |   12400 |  3.113395333 |  3.113400298 |       1 |  5.56946E+26 |            f\n",
      "  125 |   12500 |  3.113394976 |  3.113398595 |       1 |  9.46322E+26 |            f\n",
      "  126 |   12600 |  3.113394976 |  3.113397701 |       1 |  0.00000E+00 |            f\n",
      "  127 |   12700 |  3.113394976 |  3.113397129 |       1 |  0.00000E+00 |            f\n",
      "  128 |   12800 |  3.113394976 |  3.113396780 |       1 |  0.00000E+00 |            f\n",
      "  129 |   12900 |  3.113392889 |  3.113396496 |       1 |  0.024002075 |        ideal\n",
      "  130 |   13000 |  3.113392889 |  3.113396181 |       1 |  0.00000E+00 |            f\n",
      "  131 |   13100 |  3.113392889 |  3.113395889 |       1 |  0.00000E+00 |            f\n",
      "  132 |   13200 |  3.113392889 |  3.113395584 |       1 |  0.00000E+00 |            f\n",
      "  133 |   13300 |  3.113392889 |  3.113395383 |       1 |  0.00000E+00 |            f\n",
      "  134 |   13400 |  3.113392889 |  3.113395166 |       1 |  0.00000E+00 |            f\n",
      "  135 |   13500 |  3.113392889 |  3.113395034 |       1 |  0.00000E+00 |            f\n",
      "  136 |   13600 |  3.113392889 |  3.113394889 |       1 |  0.00000E+00 |            f\n",
      "  137 |   13700 |  3.113392889 |  3.113394805 |       1 |  0.00000E+00 |            f\n",
      "  138 |   13800 |  3.113392889 |  3.113394695 |       1 |  0.00000E+00 |            f\n",
      "  139 |   13900 |  3.113392889 |  3.113394599 |       1 |  0.00000E+00 |            f\n",
      "  140 |   14000 |  3.113392889 |  3.113394492 |       1 |  0.00000E+00 |            f\n",
      "  141 |   14100 |  3.113392889 |  3.113394443 |       1 |  0.00000E+00 |            f\n",
      "  142 |   14200 |  3.113392889 |  3.113394387 |       1 |  0.00000E+00 |            f\n",
      "  143 |   14300 |  3.113392889 |  3.113394306 |       1 |  0.00000E+00 |            f\n",
      "  144 |   14400 |  3.113392889 |  3.113394234 |       1 |  0.00000E+00 |            f\n",
      "  145 |   14500 |  3.113392889 |  3.113394123 |       1 |  0.00000E+00 |            f\n",
      "  146 |   14600 |  3.113392889 |  3.113394007 |       1 |  0.00000E+00 |            f\n",
      "  147 |   14700 |  3.113392889 |  3.113393916 |       1 |  0.00000E+00 |            f\n",
      "  148 |   14800 |  3.113392889 |  3.113393829 |       1 |  0.00000E+00 |            f\n",
      "  149 |   14900 |  3.113392889 |  3.113393762 |       1 |  0.00000E+00 |            f\n",
      "  150 |   15000 |  3.113392889 |  3.113393714 |       1 |  0.00000E+00 |            f\n",
      "--------------------------------------------------\n",
      "\n",
      "Optimal solutions on the initial trained model is obtained!\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Evolutionary computation routines on the Trained Model\n",
    "\n",
    "selection = define_selection(selection_operator_name)\n",
    "crossover = define_crossover(crossover_operator_name, prob=prob_c, eta=eta_c)\n",
    "mutation = define_mutation(mutation_operator_name, eta=eta_m)\n",
    "\n",
    "#EA settings\n",
    "EA = EvolutionaryAlgorithm(algorithm_name)\n",
    "algorithm = EA.setup(pop_size=pop_size,\n",
    "\t\t\t\t\t sampling=initial_sampling,\n",
    "# \t\t\t\t\t selection=selection,\n",
    "\t\t\t\t\t crossover=crossover,\n",
    "\t\t\t\t\t mutation=mutation)\n",
    "\n",
    "#Stopping criteria\n",
    "stopping_criteria_def = StoppingCriteria(termination_name)\n",
    "stopping_criteria = stopping_criteria_def.set_termination(n_gen=n_gen)\n",
    "\n",
    "#Obtaining optimal solutions on the initial trained model\n",
    "print(f'Performing optimization on the initial trained model using {algorithm_name.upper()}\\n')\n",
    "optimal_solutions =  do_optimization(TrainedModel_Problem,\n",
    "\t\t\t\t\t\t\t\t\t algorithm, stopping_criteria,\n",
    "\t\t\t\t\t\t\t\t\t verbose=True, seed=1,\n",
    "\t\t\t\t\t\t\t\t\t return_least_infeasible=False)\n",
    "print('--------------------------------------------------')\n",
    "print('\\nOptimal solutions on the initial trained model is obtained!\\n')\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-equity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-sender",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
